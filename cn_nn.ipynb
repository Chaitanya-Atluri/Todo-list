{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cn-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaitanya-Atluri/Todo-list/blob/master/cn_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTbor0Ljeuar"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# LOGISTICS\n",
        "#\n",
        "#    Your name as in eLearning\n",
        "#    Your UT Dallas identifier\n",
        "#\n",
        "\n",
        "# DESCRIPTION\n",
        "#\n",
        "#    MNIST image classification with an xNN written and trained in Python\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "#    1. Go to Google Colaboratory: https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "#    2. File - New Python 3 notebook\n",
        "#    3. Cut and paste this file into the cell (feel free to divide into multiple cells)\n",
        "#    4. Runtime - Run all\n",
        "#\n",
        "# NOTES\n",
        "#\n",
        "#    1. This does not use PyTorch, TensorFlow or any other xNN library\n",
        "#\n",
        "#    2. Include a short summary here in nn.py of what you did for the neural\n",
        "#       network portion of code\n",
        "#\n",
        "#    3. Include a short summary here in cnn.py of what you did for the\n",
        "#       convolutional neural network portion of code\n",
        "#\n",
        "#    4. Include a short summary here in extra.py of what you did for the extra\n",
        "#       portion of code\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# IMPORT\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "#\n",
        "# you should not need any import beyond the below\n",
        "# PyTorch, TensorFlow, ... is not allowed\n",
        "#\n",
        "\n",
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import math\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BI9Bqn_gadl"
      },
      "source": [
        "\n",
        "################################################################################\n",
        "#\n",
        "# PARAMETERS\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "#\n",
        "# add other hyper parameters here with some logical organization\n",
        "#\n",
        "\n",
        "# data\n",
        "DATA_NUM_TRAIN         = 60000\n",
        "DATA_NUM_TEST          = 10000\n",
        "DATA_CHANNELS          = 1\n",
        "DATA_ROWS              = 28\n",
        "DATA_COLS              = 28\n",
        "DATA_CLASSES           = 10\n",
        "DATA_URL_TRAIN_DATA    = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS  = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA     = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS   = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA   = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA    = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS  = 'test_labels.gz'\n",
        "EPOCHS                 = 5\n",
        "\n",
        "# display\n",
        "DISPLAY_ROWS   = 8\n",
        "DISPLAY_COLS   = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU-wHORDgaOI",
        "outputId": "8be57268-6e33-413d-ce04-e76c5d4df8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# DATA\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# download\n",
        "if (os.path.exists(DATA_FILE_TRAIN_DATA)   == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_DATA,   DATA_FILE_TRAIN_DATA)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_LABELS) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "if (os.path.exists(DATA_FILE_TEST_DATA)    == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_DATA,    DATA_FILE_TEST_DATA)\n",
        "if (os.path.exists(DATA_FILE_TEST_LABELS)  == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_LABELS,  DATA_FILE_TEST_LABELS)\n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data   = gzip.open(DATA_FILE_TRAIN_DATA, 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN*DATA_ROWS*DATA_COLS)\n",
        "train_data        = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float64)\n",
        "train_data        = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels   = gzip.open(DATA_FILE_TRAIN_LABELS, 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels        = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int64)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data   = gzip.open(DATA_FILE_TEST_DATA, 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST*DATA_ROWS*DATA_COLS)\n",
        "test_data        = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float64)\n",
        "test_data        = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels   = gzip.open(DATA_FILE_TEST_LABELS, 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels        = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int64)\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "print(train_data[1])\n",
        "\n",
        "# debug\n",
        "# print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "# print(train_labels.shape) # (60000,)\n",
        "# print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "# print(test_labels.shape)  # (10000,)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n",
            "   227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n",
            "   252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n",
            "   252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n",
            "   190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n",
            "    12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n",
            "     0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n",
            "     0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n",
            "     0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n",
            "     0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n",
            "   225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n",
            "   252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n",
            "   145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O4Nub_JgXe_",
        "outputId": "97d8c2ea-2baa-49ef-9d4c-2a6a4373bfe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# YOUR CODE GOES HERE\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "#\n",
        "# feel free to split this into some number of classes, functions, ... if it\n",
        "# helps with code organization; for example, you may want to create a class for\n",
        "# each of your layers that store parameters, performs initialization and\n",
        "# includes forward and backward functions\n",
        "#\n",
        "# x = np.random.random((2,2,3))\n",
        "# print(x)\n",
        "#learning rate\n",
        "lr= 0.001\n",
        "\n",
        "\n",
        "# random.seed(1)\n",
        "#one hot vector for labels\n",
        "one_hot_labels = np.zeros((train_labels.shape[0], 10))\n",
        "\n",
        "for i in range(train_labels.shape[0]):\n",
        "    one_hot_labels[i, train_labels[i]] = 1\n",
        "one_hot_labels = np.array(one_hot_labels, dtype='float32')\n",
        "\n",
        "# Relu activation function\n",
        "def relu(a, derivative=False):\n",
        "  if derivative:\n",
        "    return np.greater(a,0).astype(int)\n",
        "  else:\n",
        "    return np.maximum(0,a)\n",
        "\n",
        "def softmax(X):\n",
        "  \"\"\" applies softmax to an input x\"\"\"\n",
        "  exps = np.exp(X - np.max(X))\n",
        "  return exps / np.sum(exps)\n",
        "\n",
        "\n",
        "def cross_entropy(X,y):\n",
        "    \"\"\"\n",
        "    X is the output from fully connected layer (num_examples x num_classes)\n",
        "    y is labels (num_examples x 1)\n",
        "    \tNote that y is not one-hot encoded vector. \n",
        "    \tIt can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
        "    \"\"\"\n",
        "    m = y.shape[0]\n",
        "    p = softmax(X)\n",
        "    # We use multidimensional array indexing to extract \n",
        "    # softmax probability of the correct label for each sample.\n",
        "    # Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
        "    log_likelihood = -np.log(p[range(m),y])\n",
        "    loss = np.sum(log_likelihood) / m\n",
        "    return loss\n",
        "  \n",
        "\n",
        "def delta_cross_entropy(X,y):\n",
        "    \"\"\"\n",
        "    X is the output from fully connected layer (num_examples x num_classes)\n",
        "    y is labels (num_examples x 1)\n",
        "    \tNote that y is not one-hot encoded vector. \n",
        "    \tIt can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
        "    \"\"\"\n",
        "    m = y.shape[0]\n",
        "    grad = softmax(X)\n",
        "    grad[range(m),y] -= 1\n",
        "    grad = grad/m\n",
        "    return grad\n",
        "\n",
        "\n",
        "# normalize\n",
        "train_data = (train_data/255).astype('float32')\n",
        "test_data = (test_data/255).astype('float32')\n",
        "\n",
        "\n",
        "print(train_data[2])\n",
        "\n",
        "\n",
        "# vectorize input array\n",
        "train_data = train_data.reshape(train_data.shape[0],1,28*28)\n",
        "test_data = test_data.reshape(test_data.shape[0],1,28*28)\n",
        "\n",
        "\n",
        "# Hidden weight layer for input \n",
        "w1 = np.random.randn(train_data.shape[2], 1000)*np.sqrt(1./train_data.shape[2])\n",
        "b1 = np.random.randn(1000)\n",
        " \n",
        "# 2nd hidden layer\n",
        "w2 = np.random.randn(w1.shape[1], 100)*np.sqrt(1./w1.shape[1])\n",
        "b2 = np.random.randn(100)\n",
        "\n",
        "# 3rd hidden layer\n",
        "w3 = np.random.randn(w2.shape[1], 10)*np.sqrt(1./w2.shape[1])\n",
        "b3 = np.random.randn(10)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.2627451  0.9098039  0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.24313726 0.31764707\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.47058824 0.7058824  0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.49411765 0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.00784314 0.6        0.8235294  0.15686275 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.8627451  0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.10588235 0.99607843 0.63529414 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.87058824 0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.7176471  0.99607843 0.49019608 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.18039216 0.9607843  0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.7764706  0.99607843 0.21960784 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.47058824 0.99607843 0.6392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.09019608 0.90588236 0.99607843 0.11372549 0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.62352943 0.99607843 0.47058824\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.6392157  0.99607843 0.84705883 0.0627451  0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.62352943 0.99607843 0.2627451\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.05490196 0.3372549  0.69803923\n",
            "   0.972549   0.99607843 0.35686275 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.62352943 0.99607843 0.33333334\n",
            "   0.         0.         0.         0.18431373 0.19215687 0.45490196\n",
            "   0.5647059  0.5882353  0.94509804 0.9529412  0.91764706 0.7019608\n",
            "   0.94509804 0.9882353  0.15686275 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.5882353  0.99215686 0.92941177\n",
            "   0.8117647  0.8117647  0.8117647  0.99215686 0.99607843 0.98039216\n",
            "   0.9411765  0.7764706  0.56078434 0.35686275 0.10980392 0.01960784\n",
            "   0.9137255  0.98039216 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.46666667 0.69411767\n",
            "   0.69411767 0.69411767 0.69411767 0.69411767 0.38431373 0.21960784\n",
            "   0.         0.         0.         0.         0.         0.4\n",
            "   0.99607843 0.8627451  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.5372549  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.22352941 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.22352941 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   1.         0.36862746 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.3764706  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   0.99607843 0.6        0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.6627451\n",
            "   1.         0.6        0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.3764706\n",
            "   0.99607843 0.6        0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbWPjVplWFtb",
        "outputId": "25499b60-ee56-458f-e1ab-2a92f6ab7cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "\n",
        "# Feed forward network\n",
        "for epoch in range(1):\n",
        "  program_starts = time.time()\n",
        "  loss=0\n",
        "  for i,val in enumerate(train_data):\n",
        "    temp_input = np.copy(val)\n",
        "\n",
        "    # print(temp_input)\n",
        "    #First layer\n",
        "    x1 = np.dot(temp_input, w1)\n",
        "    z1 = np.add(x1,b1)\n",
        "    # print(z1)\n",
        "    a1 = relu(z1)\n",
        "    # print(a1)\n",
        "    #Second Layer\n",
        "    x2 = np.dot(a1, w2)\n",
        "    z2 = np.add(x2,b2)\n",
        "    a2 = relu(z2)\n",
        "\n",
        "    #Third layer\n",
        "    x3 = np.dot(a2, w3)\n",
        "    z3 = np.add(x3,b3)\n",
        "    output = softmax(z3)\n",
        "\n",
        "\n",
        "    #backprop and derivatives\n",
        "    #Final output layer dealing with softmax function\n",
        "    dcost_dz3 = output - one_hot_labels[i]\n",
        "    dz3_dw3 = a2\n",
        "    dcost_w3 = np.dot(dz3_dw3.T, dcost_dz3)\n",
        "    dcost_b3 = dcost_dz3\n",
        "    # print(dcost_w3.shape)\n",
        "    # print(dcost_b3.shape)\n",
        "\n",
        "    # Second layer derivatives\n",
        "    dz3_da2 = w3\n",
        "    dcost_da2 = np.dot(dcost_dz3 , dz3_da2.T)\n",
        "    da2_dz2 = relu(z2, derivative=True)\n",
        "    dz2_dw2 = a1\n",
        "    dcost_w2 = np.dot(dz2_dw2.T, da2_dz2 * dcost_da2)\n",
        "    dcost_b2 = dcost_da2 * da2_dz2\n",
        "    # print(dcost_w2.shape)\n",
        "    # print(dcost_b2.shape)\n",
        "\n",
        "\n",
        "     # First layer derivatives\n",
        "    dcost_dz2 = dcost_da2*da2_dz2\n",
        "    dz2_da1 = w2\n",
        "    dcost_da1 = np.dot(dcost_dz2 , dz2_da1.T)\n",
        "    da1_dz1 = relu(z1, derivative=True)\n",
        "    dz1_dw1 = temp_input\n",
        "    # print(dz3_dw3.shape)\n",
        "    dcost_w1 = np.dot(dz1_dw1.T, da1_dz1 * dcost_da1)   \n",
        "    dcost_b1 = dcost_da1 * da1_dz1\n",
        " \n",
        "\n",
        "    # Update weights\n",
        "    # print(b3.shape, dcost_b3.shape)\n",
        "    w1 -= lr * dcost_w1\n",
        "    b1 -= lr * dcost_b1.sum(axis=0)\n",
        "    w2 -= lr * dcost_w2\n",
        "    b2 -= lr * dcost_b2.sum(axis=0)\n",
        "    w3 -= lr * dcost_w3\n",
        "    b3 -= lr * dcost_b3.sum(axis=0)\n",
        "    loss = np.sum(-one_hot_labels[i] * np.log(output))\n",
        "    # if(i%200 == 0):\n",
        "    #   print(output)\n",
        "    #   print(\"Cost is:\", loss)\n",
        "  now = time.time()\n",
        "  print('Epoch: {} Loss: {:.6f} Time: {:.2f} secs'.format(epoch, loss, now-program_starts))\n",
        "# error_cost.append(loss)\n",
        "print(w2[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# output.shape\n",
        "# print(w1)\n",
        "# print(b1)\n",
        "\n",
        "  # error_out = cross_entropy(output,train_labels[i])\n",
        "    # print(error_out)\n",
        "# temp_input\n",
        "\n",
        "# cycle through the epochs\n",
        "\n",
        "    # set the learning rate\n",
        "\n",
        "    # cycle through the training data\n",
        "        # forward pass\n",
        "        # loss\n",
        "        # back prop\n",
        "        # weight update\n",
        "\n",
        "    # cycle through the testing data\n",
        "        # forward pass\n",
        "        # accuracy\n",
        "    # per epoch display (epoch, time, training loss, testing accuracy, ...)\n",
        "\n",
        "# one_hot_labels[:10]\n",
        "# train_data.shape[3]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 0.046342 Time: 0.01 secs\n",
            "[-0.05367305  0.00763779  0.07336932  0.01095054 -0.01843116  0.0224264\n",
            "  0.02115866 -0.01754726 -0.02960933 -0.01438819 -0.05227837  0.03657389\n",
            " -0.00663203  0.02059916 -0.00029619  0.02645698 -0.01984938  0.00030431\n",
            " -0.04036528 -0.05965132 -0.02643404  0.03395951  0.02703515 -0.09110154\n",
            " -0.03882302  0.01958246  0.02899009 -0.0093705   0.0548897   0.03701082\n",
            " -0.00028726  0.01786329  0.01015042  0.01053899 -0.03131747  0.00428253\n",
            "  0.0007846   0.01396954 -0.03964925  0.02828508 -0.00150268  0.06345473\n",
            " -0.03230383 -0.01003738  0.06042196 -0.00802667  0.00865151  0.06845329\n",
            "  0.01711505  0.02690829  0.01664318  0.02247241  0.04448335 -0.02958287\n",
            "  0.06151644 -0.01344439 -0.03493614 -0.01652933 -0.00968075 -0.01680624\n",
            " -0.00679727 -0.02819122 -0.06329686  0.01544511  0.05664501 -0.05152432\n",
            " -0.05561453  0.03634719 -0.05044548 -0.01289443 -0.04242103 -0.03286042\n",
            " -0.01950868  0.06073322 -0.03789038 -0.01964027  0.01104531 -0.03351736\n",
            " -0.00049904  0.07789029  0.02893388  0.09531212 -0.00504335 -0.02066091\n",
            " -0.04670384  0.02097975 -0.03592694  0.03256497 -0.0573654   0.07412036\n",
            "  0.0411144  -0.05891783 -0.00733726 -0.06491234  0.01731674  0.03003227\n",
            " -0.00708955 -0.0138606  -0.02692092 -0.00047288]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgCsououlrNz"
      },
      "source": [
        "\n",
        "import pickle\n",
        "output = open('w1.pkl', 'wb')\n",
        "pickle.dump(w1,output)\n",
        "output = open('w2.pkl', 'wb')\n",
        "pickle.dump(w2,output)\n",
        "output = open('w3.pkl', 'wb')\n",
        "pickle.dump(w3,output)\n",
        "output = open('b1.pkl', 'wb')\n",
        "pickle.dump(b1,output)\n",
        "output = open('b2.pkl', 'wb')\n",
        "pickle.dump(b2,output)\n",
        "output = open('b3.pkl', 'wb')\n",
        "pickle.dump(b3,output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awrxKMrEmKOJ",
        "outputId": "112d07a9-c7e5-4cc5-e6c9-7d90c5bc618b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.download('w2.pkl')\n",
        "files.download('w3.pkl')\n",
        "files.download('b1.pkl')\n",
        "files.download('b2.pkl')\n",
        "files.download('b3.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5f477ef3-6684-414e-8669-0faef8eb5fe0\", \"w2.pkl\", 800161)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_be8e7a43-ff83-47da-a43d-bf88ec06c66a\", \"w3.pkl\", 8160)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_29ab7713-8cb4-4c23-a2b5-5a8d8666620c\", \"b1.pkl\", 8159)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ff349976-4be6-4222-af46-c80615529840\", \"b2.pkl\", 958)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_70a66067-fbbf-4d3a-966a-0c8c739176ae\", \"b3.pkl\", 0)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ5QHf2ygW6d",
        "outputId": "8903d46b-1176-4421-e898-82e8c7fcc9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# print(w3)\n",
        "################################################################################\n",
        "#\n",
        "# DISPLAY\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "#\n",
        "# more code for you to write\n",
        "#\n",
        "test_count =0\n",
        "for i, val in enumerate(test_data):\n",
        "  x1 = np.dot(val, w1)\n",
        "  z1 = np.add(x1,b1)\n",
        "  a1 = relu(z1)\n",
        "  # print(a1)\n",
        "\n",
        "  #Second Layer\n",
        "  x2 = np.dot(a1, w2)\n",
        "  z2 = np.add(x2,b2)\n",
        "  a2 = relu(z2)\n",
        "  # print(a2)\n",
        "\n",
        "  #Third layer\n",
        "  x3 = np.dot(a2, w3)\n",
        "  z3 = np.add(x3,b3)\n",
        "  # print(z3)\n",
        "  output = softmax(z3)\n",
        "  # print(output, test_labels[i])\n",
        "  if(np.argmax(output) == test_labels[i]):\n",
        "    test_count +=1\n",
        "print(test_count)\n",
        "\n",
        "print(output.shape)\n",
        "\n",
        "print(train_labels[10])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8807\n",
            "(1, 10)\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIKXKH7xgsyJ",
        "outputId": "392fb8f6-dd07-4b50-ac0e-3cf70f3e9e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# accuracy display\n",
        "# final value\n",
        "# plot of accuracy vs epoch\n",
        "\n",
        "# performance display\n",
        "# total time\n",
        "# per layer info (type, input size, output size, parameter size, MACs, ...)\n",
        "\n",
        "# example display\n",
        "# replace the xNN predicted label with the label predicted by the network\n",
        "fig = plt.figure(figsize=(DISPLAY_COL_IN, DISPLAY_ROW_IN))\n",
        "ax  = []\n",
        "for i in range(DISPLAY_NUM):\n",
        "    img = test_data[i, :, :, :].reshape((DATA_ROWS, DATA_COLS))\n",
        "    ax.append(fig.add_subplot(DISPLAY_ROWS, DISPLAY_COLS, i + 1))\n",
        "    ax[-1].set_title('True: ' + str(test_labels[i]) + ' xNN: ' + str(test_labels[i]))\n",
        "    plt.imshow(img, cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-57086038518b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0max\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDISPLAY_NUM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_COLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDISPLAY_ROWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDISPLAY_COLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' xNN: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x1800 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZN_OqsdlQwA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}